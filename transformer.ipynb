{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, ConcatDataset, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset('dair-ai/emotion',trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_model or d_emb is embeding dimention or vector dimention\n",
    "\n",
    "d_k dimention of key or quary or value (all three are same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfAttention(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super(selfAttention,self).__init__()\n",
    "        self.emb_size=emb_size\n",
    "        self.w_k=nn.Linear(emb_size,emb_size)\n",
    "        self.w_q=nn.Linear(emb_size,emb_size)\n",
    "        self.w_v=nn.Linear(emb_size,emb_size)\n",
    "        self.out=nn.Linear(emb_size,emb_size)\n",
    "\n",
    "\n",
    "    def forward(self,k,q,v,mask):\n",
    "        K=self.w_k(k)\n",
    "        Q=self.w_q(q)\n",
    "        V=self.w_v(v)\n",
    "        attention=(torch.matmul(Q,K.transpose(-2,-1)))/torch.tensor(self.emb_size**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            attention.masked_fill_(mask==0, -1e6)\n",
    "\n",
    "        attention_scores=F.softmax(attention, dim=-1)\n",
    "        output=torch.matmul(attention_scores,V)\n",
    "        output=self.out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size, heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.heads=heads\n",
    "        self.emb_size=emb_size\n",
    "        self.head_dim=self.emb_size//self.heads\n",
    "        self.w_k=nn.Linear(emb_size,emb_size)\n",
    "        self.w_q=nn.Linear(emb_size,emb_size)\n",
    "        self.w_v=nn.Linear(emb_size,emb_size)\n",
    "        self.out=nn.Linear(emb_size,emb_size)\n",
    "\n",
    "        assert(self.head_dim * heads == emb_size),\"embeding size is not divisible by number of heads\"\n",
    "\n",
    "\n",
    "    def forward(self,k,q,v,mask=None):\n",
    "        N=q.shape[0]  # batch size\n",
    "        K=self.w_k(k)\n",
    "        Q=self.w_q(q)\n",
    "        V=self.w_v(v)\n",
    "\n",
    "        K=K.view(N,K.shape[1],self.heads,self.head_dim).transpose(1,2)    # (batch size, sequence len, heads, head dimention)\n",
    "        Q=Q.view(N,Q.shape[1],self.heads,self.head_dim).transpose(1,2)    # transposed to give(batch size, heads, sequence len, head dimention)\n",
    "        V=V.view(N,V.shape[1],self.heads,self.head_dim).transpose(1,2)\n",
    "\n",
    "        attention=(torch.matmul(Q,K.transpose(-2,-1)))/torch.tensor(self.head_dim**0.5)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask=mask.reshape(-1,1,1,128)\n",
    "            attention.masked_fill_(mask==0, -1e9)\n",
    "\n",
    "        attention_scores=F.softmax(attention, dim=-1)\n",
    "        output=torch.matmul(attention_scores,V)\n",
    "        output = output.transpose(1, 2).reshape(N, -1, self.emb_size)\n",
    "        output=self.out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_embedding(seq_len, emb_size, n=10000):\n",
    "    P = np.zeros((seq_len, emb_size))\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(emb_size // 2):\n",
    "            denominator = np.power(n, 2 * i / emb_size)\n",
    "            P[pos, 2 * i] = np.sin(pos / denominator)\n",
    "            P[pos, 2 * i + 1] = np.cos(pos / denominator)\n",
    "    return torch.tensor(P, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, heads, emb_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.mha=MultiHeadAttention(emb_size, heads)\n",
    "        self.ff1=nn.Linear(emb_size,2*emb_size)\n",
    "        self.ff2=nn.Linear(2*emb_size, emb_size)\n",
    "        self.norm1=nn.LayerNorm(emb_size)\n",
    "        self.norm2=nn.LayerNorm(emb_size)\n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attention_out=self.mha(x,x,x,mask)\n",
    "        attention_out = self.dropout(attention_out)\n",
    "        out1=self.norm1(x+attention_out)\n",
    "\n",
    "        ff_out=F.relu(self.ff1(out1))\n",
    "        ff_out=self.ff2(ff_out)\n",
    "        out2=self.dropout(ff_out)\n",
    "        encoder_out=self.norm2(out1+out2)\n",
    "        return encoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, heads, emb_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.mmha=MultiHeadAttention(emb_size, heads)\n",
    "        self.mha=MultiHeadAttention(emb_size, heads)\n",
    "        self.ff1=nn.Linear(emb_size,2*emb_size)\n",
    "        self.ff2=nn.Linear(2*emb_size, emb_size)\n",
    "        self.norm1=nn.LayerNorm(emb_size)\n",
    "        self.norm2=nn.LayerNorm(emb_size)\n",
    "        self.norm3=nn.LayerNorm(emb_size)\n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x, encoder_out, source_mask, target_mask):\n",
    "        mask_attention_out=self.mmha(x,x,x,target_mask)\n",
    "        mask_attention_out=self.dropout(mask_attention_out)\n",
    "        out1=self.norm1(x+mask_attention_out)\n",
    "\n",
    "        enc_dec_attention_out=self.mha(encoder_out,out1,encoder_out)\n",
    "        enc_dec_attention_out=self.dropout(enc_dec_attention_out)\n",
    "        out2=self.norm2(out1+enc_dec_attention_out)\n",
    "\n",
    "        ff_output=F.relu(self.ff1(out2))\n",
    "        ff_output=self.ff2(ff_output)\n",
    "        ff_output=self.dropout(ff_output)\n",
    "        out3=self.norm3(out2+ff_output)\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, input_dim, emb_size, num_encoder_layers, num_decoder_layers, heads, seq_len, out_class):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.embedding=nn.Embedding(vocab_size, emb_size)\n",
    "        self.encoder_layers = nn.ModuleList([Encoder(heads, emb_size) for _ in range(num_encoder_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([Decoder(heads, emb_size) for _ in range(num_decoder_layers)])\n",
    "        self.position_encodings = pos_embedding(seq_len, emb_size)\n",
    "        self.linear = nn.Linear(emb_size, out_class)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "\n",
    "        src=self.embedding(src)   # need to do *sqrt(d_model)\n",
    "        tgt=self.embedding(tgt)   # for transulation task give different embedding\n",
    "\n",
    "        for encoder in self.encoder_layers:\n",
    "            src = encoder(src, src_mask)\n",
    "        \n",
    "        for decoder in self.decoder_layers:\n",
    "            tgt = decoder(tgt, src, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.linear(tgt[:, -1, :])\n",
    "        output = F.softmax(output, dim=-1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "\n",
    "input_dim = 1000\n",
    "emb_size = 512\n",
    "heads = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "num_classes = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Preprocess data\\ndef preprocess_function(examples):\\n    return tokenizer(examples['text'], truncation=True, padding=True, max_length=128)\\n\\n# Split dataset\\ntrain_data = dataset['train'].map(preprocess_function, batched=True)\\ntest_data = dataset['test'].map(preprocess_function, batched=True)\\n\\n# Create data loaders\\ntrain_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\\ntest_dataloader = DataLoader(test_data, batch_size=16)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Preprocess data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Split dataset\n",
    "train_data = dataset['train'].map(preprocess_function, batched=True)\n",
    "test_data = dataset['test'].map(preprocess_function, batched=True)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=16)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class CustomDataset(Dataset):\\n    def __init__(self, data, tokenizer, max_length):\\n        self.data = data\\n        self.tokenizer = tokenizer\\n        self.max_length = max_length\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, idx):\\n        item = self.data[idx]\\n        encoding = self.tokenizer(\\n            item['text'], \\n            padding='max_length', \\n            truncation=True, \\n            max_length=self.max_length, \\n            return_tensors='pt'\\n        )\\n        input_ids = encoding['input_ids'].squeeze(0)  # Remove batch dimension\\n        attention_mask = encoding['attention_mask'].squeeze(0)  # Remove batch dimension\\n        label = torch.tensor(item['label'], dtype=torch.long)\\n        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}\\n\\ndef collate_fn(batch):\\n    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True, padding_value=0)\\n    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True, padding_value=0)\\n    labels = torch.tensor([item['label'] for item in batch], dtype=torch.long)\\n    \\n    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': labels}\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            item['text'], \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_length, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze(0)  # Remove batch dimension\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)  # Remove batch dimension\n",
    "        label = torch.tensor(item['label'], dtype=torch.long)\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True, padding_value=0)\n",
    "    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor([item['label'] for item in batch], dtype=torch.long)\n",
    "    \n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': labels}'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\\nmax_length = 128  # Or any other desired max length\\n\\ntrain_dataset = CustomDataset(train_data, tokenizer, max_length)\\ntest_dataset = CustomDataset(test_data, tokenizer, max_length)\\n\\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)\\ntest_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_length = 128  # Or any other desired max length\n",
    "\n",
    "train_dataset = CustomDataset(train_data, tokenizer, max_length)\n",
    "test_dataset = CustomDataset(test_data, tokenizer, max_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = Transformer(input_dim, emb_size, num_encoder_layers, num_decoder_layers, heads, seq_len=128, out_class=num_classes)\\nloss_fn = nn.CrossEntropyLoss()\\noptimizer = optim.Adam(model.parameters(), lr=3e-5)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = Transformer(input_dim, emb_size, num_encoder_layers, num_decoder_layers, heads, seq_len=128, out_class=num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from prettytable import PrettyTable\\ndef count_parameters(model):\\n    table = PrettyTable([\"Modules\", \"Parameters\"])\\n    total_params = 0\\n    for name, parameter in model.named_parameters():\\n        if not parameter.requires_grad: continue\\n        params = parameter.numel()\\n        table.add_row([name, params])\\n        total_params+=params\\n    print(table)\\n    print(f\"Total Trainable Params: {total_params}\")\\n    return total_params\\ncount_parameters(model)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "count_parameters(model)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Training loop\\nnum_epochs = 3\\nfor epoch in range(num_epochs):\\n    model.train()\\n    for batch in train_dataloader:\\n        optimizer.zero_grad()\\n        outputs = model(batch['input_ids'], batch['attention_mask'])\\n        loss = loss_fn(outputs, batch['label'])\\n        loss.backward()\\n        optimizer.step()\\n\\n    # Evaluation\\n    model.eval()\\n    total, correct = 0, 0\\n    with torch.no_grad():\\n        for batch in test_dataloader:\\n            outputs = model(batch['input_ids'], batch['attention_mask'])\\n            _, predicted = torch.max(outputs, dim=1)\\n            total += batch['label'].size(0)\\n            correct += (predicted == batch['label']).sum().item()\\n\\n    accuracy = correct / total\\n    print(f'Epoch {epoch + 1}, Accuracy: {accuracy:.4f}')\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "        loss = loss_fn(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += batch['label'].size(0)\n",
    "            correct += (predicted == batch['label']).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch + 1}, Accuracy: {accuracy:.4f}')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embedding): Embedding(30522, 512)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-5): 6 x Encoder(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (ff1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (ff2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-5): 6 x Decoder(\n",
       "      (mmha): MultiHeadAttention(\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (ff1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (ff2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "# Split dataset\n",
    "train_data = dataset['train'].map(preprocess_function, batched=True) \n",
    "test_data = dataset['test'].map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.data[idx]['input_ids']),\n",
    "            'attention_mask': torch.tensor(self.data[idx]['attention_mask']),\n",
    "            'label': torch.tensor(self.data[idx]['label'])\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    labels = torch.stack([item['label'] for item in batch])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': labels}\n",
    "\n",
    "train_dataset = EmotionDataset(train_data)\n",
    "test_dataset = EmotionDataset(test_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)#, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)#, collate_fn=collate_fn)\n",
    "\n",
    "model = Transformer(tokenizer.vocab_size, input_dim, emb_size, num_encoder_layers, num_decoder_layers, heads, seq_len=128, out_class=num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    model = model.to('cuda')    #transfer model to GPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9999e-01, 2.3023e-06, 3.4305e-06, 3.9553e-06, 2.5020e-07, 3.8796e-06]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example={'text': 'im sad'}\n",
    "ex=preprocess_function(example)\n",
    "ex=EmotionDataset(example)\n",
    "exa=DataLoader(test_dataset,batch_size=1)\n",
    "first_item1=next(iter(exa))\n",
    "if torch.cuda.is_available():\n",
    "    first_item1['input_ids'], first_item1['input_ids'], first_item1['attention_mask']=first_item1['input_ids'].to(device), first_item1['input_ids'].to(device), first_item1['attention_mask'].to(device)\n",
    "model(first_item1['input_ids'], first_item1['input_ids'], first_item1['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.6345e-02, 1.1440e-03, 1.7689e-04, 5.7809e-01, 3.6413e-01, 1.1578e-04],\n",
       "        [9.9998e-01, 2.9373e-06, 3.7329e-06, 3.9547e-06, 2.2876e-07, 4.2140e-06],\n",
       "        [9.9998e-01, 1.0697e-06, 2.6520e-06, 1.0821e-05, 4.1099e-07, 2.8447e-06],\n",
       "        [9.9998e-01, 4.6575e-06, 3.9846e-06, 2.8538e-06, 2.1702e-07, 4.4364e-06],\n",
       "        [5.7908e-01, 2.4149e-05, 7.7338e-05, 4.1753e-01, 3.2243e-03, 6.4226e-05],\n",
       "        [1.4327e-05, 9.9998e-01, 2.7647e-06, 3.0323e-07, 3.1619e-06, 1.8826e-06],\n",
       "        [9.9999e-01, 1.9794e-06, 3.3971e-06, 5.2014e-06, 2.4658e-07, 3.9246e-06],\n",
       "        [1.6480e-05, 9.9998e-01, 2.8080e-06, 3.2522e-07, 2.7632e-06, 1.8699e-06],\n",
       "        [1.7811e-05, 9.9997e-01, 3.3069e-06, 3.4454e-07, 2.3666e-06, 2.3356e-06],\n",
       "        [7.5162e-06, 9.9998e-01, 1.6360e-06, 3.7525e-07, 4.4812e-06, 1.1284e-06],\n",
       "        [9.9998e-01, 1.5245e-06, 3.2256e-06, 6.8325e-06, 2.7111e-07, 3.4376e-06],\n",
       "        [9.9999e-01, 2.5351e-06, 3.3165e-06, 4.8161e-06, 2.3028e-07, 3.7619e-06],\n",
       "        [9.9998e-01, 2.8499e-06, 3.8374e-06, 4.2701e-06, 2.1569e-07, 4.4532e-06],\n",
       "        [9.9999e-01, 2.2780e-06, 2.2467e-06, 6.9498e-06, 4.0432e-07, 2.2985e-06],\n",
       "        [3.0518e-02, 9.9633e-04, 1.3545e-04, 8.2038e-01, 1.4789e-01, 7.7300e-05],\n",
       "        [9.9998e-01, 3.2368e-06, 3.9855e-06, 3.1645e-06, 2.3800e-07, 4.4581e-06]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_item = next(iter(train_dataloader))\n",
    "if torch.cuda.is_available():\n",
    "    first_item['input_ids'], first_item['input_ids'], first_item['attention_mask']=first_item['input_ids'].to(device), first_item['input_ids'].to(device), first_item['attention_mask'].to(device)\n",
    "model.eval()\n",
    "model(first_item['input_ids'], first_item['input_ids'], first_item['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:58<00:00,  2.79it/s]\n",
      "100%|██████████| 125/125 [00:18<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 0.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:07<00:00,  2.72it/s]\n",
      "100%|██████████| 125/125 [00:16<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Accuracy: 0.5960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:42<00:00,  2.92it/s]\n",
      "100%|██████████| 125/125 [00:18<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Accuracy: 0.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        if torch.cuda.is_available():\n",
    "            batch['input_ids'], batch['input_ids'], batch['attention_mask'] , batch['label'] = batch['input_ids'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
    "        outputs = model(batch['input_ids'], tgt=batch['input_ids'], src_mask=batch['attention_mask'])\n",
    "        loss = loss_fn(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            if torch.cuda.is_available():\n",
    "                batch['input_ids'], batch['input_ids'], batch['attention_mask'] , batch['label'] = batch['input_ids'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
    "            outputs = model(batch['input_ids'], tgt=batch['input_ids'], src_mask=batch['attention_mask'])\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += batch['label'].size(0)\n",
    "            correct += (predicted == batch['label']).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch + 1}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20362bd9bd254e36a228cde71b3a73b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data = dataset['validation'].map(preprocess_function, batched=True)\n",
    "val_dataset = EmotionDataset(val_data)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)#, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:17<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            batch['input_ids'], batch['input_ids'], batch['attention_mask'] , batch['label'] = batch['input_ids'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
    "        outputs = model(batch['input_ids'], tgt=batch['input_ids'], src_mask=batch['attention_mask'])\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += batch['label'].size(0)\n",
    "        correct += (predicted == batch['label']).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Epoch {epoch + 1}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sample: {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3}\n",
      "Processed Sample: {'input_ids': [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Display a sample before and after preprocessing\n",
    "sample = dataset['train'][2]\n",
    "print(\"Original Sample:\", sample)\n",
    "\n",
    "# Apply preprocessing\n",
    "processed_sample = preprocess_function(sample)\n",
    "print(\"Processed Sample:\", processed_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final test\n",
    "im aging very fast   fear or sadness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
